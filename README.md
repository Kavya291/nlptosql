# NLP to SQL
This project is a web-based application built with Streamlit that allows users to query a structured student dataset using natural language. The system translates user queries into executable SQL statements using a local large language model (DeepSeek) served via Ollama. The application also integrates a Retrieval-Augmented Generation (RAG) mechanism to enhance the quality and consistency of SQL generation using previously stored examples.

#Features
Accepts user queries in natural language and generates corresponding SQL queries.

Utilizes a locally hosted DeepSeek LLM via Ollama to perform language-to-SQL translation.

Supports uploading Excel files and automatically storing the data into a local SQLite database.

Incorporates a RAG pipeline using TF-IDF to retrieve and embed similar example questions from a local database for context-aware prompt construction.

Validates the SQL query before execution to ensure only the SQL part is executed and any unrelated language model output is excluded.

Restricts execution of write operations (INSERT, UPDATE, DELETE, DROP) to administrators using password authentication.

Allows users to optionally save effective Q&A pairs for future improvement of the RAG engine.

#Folder Structure
The application consists of the following files:

Home_Page.py: Main Streamlit application script.

students.db: SQLite database generated dynamically from uploaded Excel files.

examples.db: Stores past natural language questions and corresponding SQL queries for RAG.

.env: Stores environment variables such as the admin password.

requirements.txt: Lists the required Python dependencies.

README.md: Documentation of the project.

architecture.png : The overall flow of this project is depicted.

students.xlsx : An example xlsx file to upload.

#Installation

1.Clone the repository:

git clone https://github.com/kavya291/nlptosql.git
cd nlptosql

2.Create and activate a virtual environment:
python -m venv venv
source venv/bin/activate   # On Windows use: venv\Scripts\activate

3.Install dependencies:
pip install -r requirements.txt

4.Create a .env file with the admin password:
ADMIN_PASSWORD=your_admin_password

5.Ensure that the Ollama service is running locally and that the DeepSeek model is available. 

6.To launch the Streamlit app, use the following command:
streamlit run Home_Page.py
This will open the application in your browser where you can upload an Excel file, ask natural language questions, and retrieve answers from the database.

#Usage Instructions
Upload an Excel file containing student data. The application will create or update students.db accordingly.

Type your question in natural language. For example: “Show students with CGPA above 8 and location Bangalore”.

The system retrieves relevant examples from examples.db, constructs a prompt, and queries the DeepSeek model via Ollama.

The SQL query is extracted, validated, and executed on the SQLite database.

Optionally, you can save the successful question-SQL pair for future reference.

For queries involving write operations, admin authentication is required.

#Security and Access Control
Only SQL statements are executed. Any explanation or additional text generated by the LLM is filtered out.

For security, write operations (INSERT, UPDATE, DELETE, DROP) require admin access, authenticated via a password defined in the .env file.

#Technical Notes
Uses TF-IDF and cosine similarity to rank and retrieve similar questions for RAG.

SQLite is used for simplicity and easy integration with Streamlit.

Excel parsing is handled using openpyxl.

Prompt construction includes schema and formatting examples to guide the LLM.

#Requirements
Python 3.8 or above

Streamlit

SQLite3

Ollama installed and running locally with a compatible DeepSeek model

Author
Kavya M M
